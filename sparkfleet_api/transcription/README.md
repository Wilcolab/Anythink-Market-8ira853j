# Automated Transcription & Summarization

‚úÖ **IMPLEMENTED**: Meetings can be transcribed and summarized automatically after call ends

## Overview

This module provides automatic transcription and summarization of meeting audio after calls end. It processes meetings from Zoom/GMeet and extracts:

- Full transcription of the meeting
- Key discussion points
- Decisions made
- Action items with assignees

## Features

- **Automatic Processing**: Webhook integration triggers processing when meetings end
- **Transcription**: Audio-to-text conversion (currently using mock/stub, ready for Whisper integration)
- **Summarization**: AI-powered extraction of key points and decisions
- **Action Item Detection**: Identifies commitments and assigns them to team members
- **Confidence Scores**: Each extracted item includes a confidence score
- **Platform Support**: Works with Zoom and Google Meet

## Components

### Data Models (`models.py`)

- `Meeting`: Represents a meeting session with metadata
- `Transcription`: Stores the transcribed text with segments
- `Summary`: Contains key points, decisions, and action items
- `ActionItem`: Represents individual tasks with assignees and confidence

### Services

1. **TranscriptionService** (`transcription_service.py`)
   - Transcribes meeting audio to text
   - Currently uses mock transcription (ready for Whisper API integration)
   - Returns structured transcription with confidence scores

2. **SummarizationService** (`summarization_service.py`)
   - Extracts key discussion points
   - Identifies decisions made during the meeting
   - Detects action items and potential assignees
   - Generates formatted summary text

3. **MeetingProcessor** (`meeting_processor.py`)
   - Orchestrates the complete processing flow
   - Manages meeting status transitions
   - Coordinates transcription and summarization

4. **WebhookHandler** (`webhook_handler.py`)
   - Receives webhook events from meeting platforms
   - Parses platform-specific payloads
   - Triggers automatic processing

## Usage

### Basic Usage

```python
from sparkfleet_api.transcription import (
    Meeting, MeetingPlatform, MeetingStatus, MeetingProcessor
)
from datetime import datetime

# Create a meeting that has ended
meeting = Meeting(
    id="meeting-123",
    title="Product Planning",
    platform=MeetingPlatform.ZOOM,
    start_time=datetime.utcnow(),
    status=MeetingStatus.ENDED,
    audio_url="https://zoom.us/rec/play/abc123"
)

# Process the meeting
processor = MeetingProcessor()
transcription, summary = processor.process_meeting_end(meeting)

# Access results
print(f"Transcription: {transcription.text}")
print(f"Key Points: {summary.key_points}")
print(f"Decisions: {summary.decisions}")
print(f"Action Items: {len(summary.action_items)}")
```

### Webhook Integration

```python
from sparkfleet_api.transcription import TranscriptionAPI

api = TranscriptionAPI()

# Handle Zoom webhook
zoom_payload = {
    "platform": "zoom",
    "meeting_id": "123456789",
    "topic": "Team Standup",
    "start_time": "2024-01-15T10:00:00",
    "participants": ["alice@company.com", "bob@company.com"],
    "recording_url": "https://zoom.us/rec/play/meeting-recording"
}

result = api.webhook_meeting_ended(zoom_payload)
print(result)  # Returns summary with key points, decisions, and action items
```

### Manual Processing

```python
from sparkfleet_api.transcription import TranscriptionAPI

api = TranscriptionAPI()

# Manually trigger processing
result = api.process_meeting_manually(
    meeting_id="meeting-456",
    audio_url="https://storage.example.com/audio.mp3"
)

print(result["summary"]["action_items"])
```

## Demo

Run the included demo to see the system in action:

```bash
python sparkfleet_api/transcription/demo.py
```

The demo demonstrates:
- Complete meeting processing flow
- Webhook integration
- Summary generation with key points, decisions, and action items

## Next Steps

### Integration Points

1. **Transcription API Integration**
   - Replace mock transcription in `TranscriptionService._mock_transcribe()`
   - Integrate with OpenAI Whisper, Google Speech-to-Text, or similar
   - Add support for multiple languages

2. **AI/LLM Integration for Summarization**
   - Enhance `SummarizationService` with GPT-4 or Claude
   - Improve action item detection accuracy
   - Better assignee extraction

3. **Platform Webhooks**
   - Set up Zoom webhook endpoint
   - Configure Google Meet webhook
   - Handle authentication and verification

4. **Storage & Persistence**
   - Add database storage for meetings, transcriptions, and summaries
   - Implement retrieval APIs
   - Add search functionality

5. **UI Integration**
   - Display summaries in SparkFleet dashboard
   - Allow users to edit/approve summaries
   - Show confidence scores for review

## Architecture

```
Meeting End Event (Zoom/GMeet)
         ‚Üì
    WebhookHandler
         ‚Üì
   MeetingProcessor
         ‚Üì
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚Üì           ‚Üì
TranscriptionService ‚Üí SummarizationService
   ‚Üì                    ‚Üì
Transcription    ‚Üí   Summary (Key Points, Decisions, Action Items)
```

## Configuration

The services are designed to be easily configured:

- Transcription engine can be switched (Whisper, Google, etc.)
- Summarization model can be configured (GPT-4, Claude, etc.)
- Confidence thresholds can be adjusted
- Processing timeouts can be set

## Testing

The module includes a comprehensive demo that validates:
- Meeting creation and status management
- Transcription processing
- Summary generation
- Action item extraction
- Webhook handling

Run tests with:
```bash
python sparkfleet_api/transcription/demo.py
```

## Status

‚úÖ Core functionality implemented and working
‚úÖ Webhook integration ready
‚úÖ Demo validates complete flow
üîÑ Ready for production API integration (Whisper, GPT-4)
üîÑ Ready for database integration
üîÑ Ready for UI integration